"""
Dynamic Query Mechanism for Adaptive Object Detection
åŠ¨æ€æŸ¥è¯¢æœºåˆ¶ï¼šåŸºäºå¯å­¦ä¹ è¾¹ç•Œå’Œè½¯åŒºé—´åˆ†é…
å®Œå…¨é‡å†™ç‰ˆæœ¬ï¼Œç¡®ä¿æ•°å€¼ç¨³å®šæ€§
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import math
import sys
import os

# æ·»åŠ è·¯å¾„ä»¥å¯¼å…¥å®‰å…¨å·¥å…·
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))



def safe_prob_normalize(probs, eps=1e-6):
    """å®‰å…¨çš„æ¦‚ç‡å½’ä¸€åŒ–"""
    probs = torch.clamp(probs, min=0.0)  # ç¡®ä¿éè´Ÿ
    denom = probs.sum(dim=1, keepdim=True)
    denom = torch.clamp(denom, min=eps)  # é˜²æ­¢é™¤é›¶
    return probs / denom


class LearnableBoundaryPredictor(nn.Module):
    """
    å¯å­¦ä¹ è¾¹ç•Œé¢„æµ‹å™¨ - æ•°å€¼ç¨³å®šç‰ˆæœ¬
    """

    def __init__(self, feature_dim=256, num_boundaries=3, max_objects=1500,
                 initial_smoothness=1.0):
        super().__init__()
        self.num_boundaries = num_boundaries
        self.max_objects = max_objects

        # å…¨å±€ç‰¹å¾æå–
        self.global_pool_avg = nn.AdaptiveAvgPool2d(1)
        self.global_pool_max = nn.AdaptiveMaxPool2d(1)

        # è¾¹ç•Œé¢„æµ‹ç½‘ç»œ - ä½¿ç”¨æ›´ä¿å®ˆçš„åˆå§‹åŒ–
        self.boundary_predictor = nn.Sequential(
            nn.Linear(feature_dim * 2, feature_dim),
            nn.LayerNorm(feature_dim),  # ä½¿ç”¨ LayerNorm æé«˜ç¨³å®šæ€§
            nn.ReLU(inplace=True),
            nn.Dropout(0.1),
            nn.Linear(feature_dim, feature_dim // 2),
            nn.LayerNorm(feature_dim // 2),
            nn.ReLU(inplace=True),
            nn.Linear(feature_dim // 2, num_boundaries)
        )

        # å¹³æ»‘ç³»æ•°ï¼ˆå›ºå®šæˆ–å¯å­¦ä¹ ï¼‰
        self.register_buffer('smoothness', torch.tensor(initial_smoothness))

        # ğŸ”¥ ä¿å®ˆçš„åˆå§‹åŒ–
        self._init_weights()

    def _init_weights(self):
        """ä¿å®ˆçš„æƒé‡åˆå§‹åŒ–"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                # ä½¿ç”¨æ›´å°çš„åˆå§‹åŒ–èŒƒå›´
                nn.init.xavier_uniform_(m.weight, gain=0.1)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0.0)

        # æœ€åä¸€å±‚ç‰¹æ®Šåˆå§‹åŒ–ï¼Œä½¿åˆå§‹è¾“å‡ºæ¥è¿‘ 0
        nn.init.constant_(self.boundary_predictor[-1].weight, 0.01)
        nn.init.constant_(self.boundary_predictor[-1].bias, 0.0)

    def forward(self, density_feature):
        """
        å‰å‘ä¼ æ’­ - å®Œå…¨é‡å†™ï¼Œç¡®ä¿æ•°å€¼ç¨³å®š
        """
        # ğŸ”¥ Step 1: è¾“å…¥æ¸…ç†
        density_feature = sanitize_tensor(
            density_feature,
            name="density_feature",
            default_value=0.0,
            min_val=-5.0,
            max_val=5.0
        )

        # ğŸ”¥ Step 2: å…¨å±€ç‰¹å¾æå–ï¼ˆå¸¦ä¿æŠ¤ï¼‰
        try:
            feat_avg = self.global_pool_avg(density_feature).flatten(1)
            feat_max = self.global_pool_max(density_feature).flatten(1)
        except Exception as e:
            print(f"âŒ Pooling error: {e}")
            BS, C = density_feature.shape[0], density_feature.shape[1]
            feat_avg = torch.zeros(BS, C, device=density_feature.device)
            feat_max = torch.zeros(BS, C, device=density_feature.device)

        # æ¸…ç†ç‰¹å¾
        feat_avg = sanitize_tensor(feat_avg, "feat_avg", min_val=-5.0, max_val=5.0)
        feat_max = sanitize_tensor(feat_max, "feat_max", min_val=-5.0, max_val=5.0)

        global_feat = torch.cat([feat_avg, feat_max], dim=1)

        # ğŸ”¥ Step 3: é¢„æµ‹åŸå§‹è¾¹ç•Œï¼ˆå¸¦é™åˆ¶ï¼‰
        raw_boundaries = self.boundary_predictor(global_feat)
        raw_boundaries = torch.clamp(raw_boundaries, min=-3.0, max=3.0)

        # ğŸ”¥ Step 4: ä½¿ç”¨æ›´ç¨³å®šçš„å•è°ƒé€’å¢ç­–ç•¥
        # ç­–ç•¥ï¼šb1, b2, b3 ç›´æ¥é¢„æµ‹ä¸ºé€’å¢åºåˆ—
        # ä½¿ç”¨ softmax æ¥è‡ªåŠ¨ä¿è¯æƒé‡ä¸ºæ­£ä¸”å’Œä¸º1
        weights = F.softmax(raw_boundaries, dim=1)  # (BS, 3)

        # è¾¹ç•Œç­‰äºç´¯ç§¯æƒé‡ * max_objects
        boundaries = torch.cumsum(weights, dim=1) * self.max_objects * 0.9

        # æœ€ç»ˆä¿æŠ¤
        boundaries = torch.clamp(boundaries, min=10.0, max=self.max_objects * 0.95)

        # ç¡®ä¿ä¸¥æ ¼é€’å¢ï¼ˆæ•°å€¼ä¿®æ­£ï¼‰
        for i in range(1, boundaries.shape[1]):
            boundaries[:, i] = torch.max(
                boundaries[:, i],
                boundaries[:, i-1] + 5.0  # æœ€å°é—´éš”
            )

        return boundaries, raw_boundaries

    def compute_interval_probabilities(self, boundaries, real_count):
        """
        è®¡ç®—è½¯åŒºé—´æ¦‚ç‡ - ä½¿ç”¨æ›´ç¨³å®šçš„å…¬å¼
        """
        b1, b2, b3 = boundaries[:, 0], boundaries[:, 1], boundaries[:, 2]
        N = real_count.float().unsqueeze(1)  # (BS, 1)
        r = torch.clamp(self.smoothness, min=0.5, max=3.0)

        # ğŸ”¥ ä½¿ç”¨æŒ‡æ•°è¡°å‡çš„è½¯æŒ‡ç¤ºå‡½æ•°ï¼Œæ¯” sigmoid æ›´ç¨³å®š
        def soft_indicator(x, center, width):
            """
            è½¯æŒ‡ç¤ºå‡½æ•°ï¼šåœ¨ center é™„è¿‘ä¸º 1ï¼Œè¿œç¦»æ—¶è¡°å‡
            ä½¿ç”¨é«˜æ–¯å‹å‡½æ•°
            """
            dist = (x - center) / (width + 1e-6)
            return torch.exp(-0.5 * dist ** 2)

        # è®¡ç®—å››ä¸ªåŒºé—´çš„ä¸­å¿ƒ
        c1 = b1 / 2
        c2 = (b1 + b2) / 2
        c3 = (b2 + b3) / 2
        c4 = (b3 + self.max_objects) / 2

        # è®¡ç®—æ¯ä¸ªåŒºé—´çš„å®½åº¦
        w1 = b1 / 2 + r
        w2 = (b2 - b1) / 2 + r
        w3 = (b3 - b2) / 2 + r
        w4 = (self.max_objects - b3) / 2 + r

        # è®¡ç®—æ¦‚ç‡
        p1 = soft_indicator(N, c1.unsqueeze(1), w1.unsqueeze(1))
        p2 = soft_indicator(N, c2.unsqueeze(1), w2.unsqueeze(1))
        p3 = soft_indicator(N, c3.unsqueeze(1), w3.unsqueeze(1))
        p4 = soft_indicator(N, c4.unsqueeze(1), w4.unsqueeze(1))

        probs = torch.cat([p1, p2, p3, p4], dim=1)
        probs = safe_prob_normalize(probs)

        return probs

    def get_query_number(self, boundaries, predicted_count, query_levels):
        """æ¨ç†é˜¶æ®µï¼šç¡®å®šæŸ¥è¯¢æ•°é‡"""
        BS = boundaries.shape[0]
        device = boundaries.device

        b1, b2, b3 = boundaries[:, 0], boundaries[:, 1], boundaries[:, 2]
        N = predicted_count.float()

        num_queries = torch.zeros(BS, dtype=torch.long, device=device)

        mask1 = N <= b1
        mask2 = (N > b1) & (N <= b2)
        mask3 = (N > b2) & (N <= b3)
        mask4 = N > b3

        num_queries[mask1] = query_levels[0]
        num_queries[mask2] = query_levels[1]
        num_queries[mask3] = query_levels[2]
        num_queries[mask4] = query_levels[3]

        return num_queries

    def update_smoothness(self, epoch, total_epochs, min_smoothness=0.5):
        """åŠ¨æ€è°ƒæ•´å¹³æ»‘ç³»æ•°"""
        if epoch == 0:
            return

        current = self.smoothness.item()
        target = min_smoothness
        decay_rate = (current - target) / total_epochs
        new_value = max(current - decay_rate, target)

        self.smoothness.fill_(new_value)


class QualityAwareQueryInitializer(nn.Module):
    """
    è´¨é‡æ„ŸçŸ¥çš„æŸ¥è¯¢åˆå§‹åŒ– - æ•°å€¼ç¨³å®šç‰ˆæœ¬
    """

    def __init__(self, feature_dim=256, num_heads=8, max_queries=1500):
        super().__init__()
        self.feature_dim = feature_dim
        self.max_queries = max_queries

        # ğŸ”¥ ç®€åŒ–ç½‘ç»œç»“æ„ï¼Œæé«˜ç¨³å®šæ€§
        # é€šé“æ³¨æ„åŠ›
        self.channel_attention = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(feature_dim, feature_dim // 16, 1),
            nn.LayerNorm([feature_dim // 16, 1, 1]),  # æ·»åŠ å½’ä¸€åŒ–
            nn.ReLU(inplace=True),
            nn.Conv2d(feature_dim // 16, feature_dim, 1),
            nn.Sigmoid()
        )

        # ç©ºé—´æ³¨æ„åŠ›
        self.spatial_attention = nn.Sequential(
            nn.Conv2d(2, 1, kernel_size=7, padding=3),
            nn.Sigmoid()
        )

        # è´¨é‡é¢„æµ‹
        self.quality_predictor = nn.Sequential(
            nn.Conv2d(feature_dim, feature_dim // 2, 3, padding=1),
            nn.GroupNorm(32, feature_dim // 2),  # ä½¿ç”¨ GroupNorm
            nn.ReLU(inplace=True),
            nn.Conv2d(feature_dim // 2, 1, 1),
            nn.Sigmoid()
        )

        # åæ ‡å›å½’
        self.coord_regressor = nn.Sequential(
            nn.Conv2d(feature_dim, feature_dim // 2, 3, padding=1),
            nn.GroupNorm(32, feature_dim // 2),
            nn.ReLU(inplace=True),
            nn.Conv2d(feature_dim // 2, 4, 1),
            nn.Sigmoid()
        )

        # ä¿å®ˆåˆå§‹åŒ–
        self._init_weights()

    def _init_weights(self):
        """ä¿å®ˆåˆå§‹åŒ–"""
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.xavier_uniform_(m.weight, gain=0.1)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0.0)

    def forward(self, encoder_features, num_queries):
        """
        å‰å‘ä¼ æ’­ - å®Œå…¨é‡å†™
        """
        BS, C, H, W = encoder_features.shape
        device = encoder_features.device

        # ğŸ”¥ Step 1: è¾“å…¥æ¸…ç†
        encoder_features = sanitize_tensor(
            encoder_features,
            name="encoder_features",
            min_val=-5.0,
            max_val=5.0
        )

        # å¤„ç†æ ‡é‡è¾“å…¥
        if isinstance(num_queries, int):
            num_queries = torch.full((BS,), num_queries, dtype=torch.long, device=device)

        # ğŸ”¥ Step 2: å¤„ç†ç©ºç‰¹å¾å›¾
        if H == 0 or W == 0 or H * W < 10:
            print(f"âš ï¸ Warning: Invalid feature map size (H={H}, W={W})")
            max_K = num_queries.max().item()
            # è¿”å›ä¸­å¿ƒä½ç½®çš„é»˜è®¤æ¡†
            reference_points = torch.zeros(BS, max_K, 4, device=device)
            reference_points[..., :2] = 0.5  # ä¸­å¿ƒä½ç½®
            reference_points[..., 2:] = 0.1  # å°å°ºå¯¸
            quality_scores = torch.ones(BS, max_K, device=device) * 0.5
            return reference_points, quality_scores

        # ğŸ”¥ Step 3: æ³¨æ„åŠ›æœºåˆ¶ï¼ˆå¸¦å¼‚å¸¸å¤„ç†ï¼‰
        try:
            # é€šé“æ³¨æ„åŠ›
            channel_attn = self.channel_attention(encoder_features)
            channel_attn = torch.clamp(channel_attn, min=0.0, max=1.0)
            feat_ca = encoder_features * channel_attn

            # ç©ºé—´æ³¨æ„åŠ›
            feat_max = torch.max(feat_ca, dim=1, keepdim=True)[0]
            feat_avg = torch.mean(feat_ca, dim=1, keepdim=True)
            spatial_input = torch.cat([feat_max, feat_avg], dim=1)
            spatial_attn = self.spatial_attention(spatial_input)
            spatial_attn = torch.clamp(spatial_attn, min=0.0, max=1.0)
            feat_refined = feat_ca * spatial_attn

        except Exception as e:
            print(f"âŒ Attention error: {e}")
            feat_refined = encoder_features

        # æ¸…ç†ç‰¹å¾
        feat_refined = sanitize_tensor(feat_refined, "feat_refined")

        # ğŸ”¥ Step 4: è´¨é‡é¢„æµ‹
        quality_map = self.quality_predictor(feat_refined).squeeze(1)
        quality_map = torch.clamp(quality_map, min=0.0, max=1.0)

        # ğŸ”¥ Step 5: åæ ‡å›å½’ï¼ˆå…³é”®ï¼šä¸¥æ ¼é™åˆ¶èŒƒå›´ï¼‰
        coords_map = self.coord_regressor(feat_refined).permute(0, 2, 3, 1)
        # é™åˆ¶åœ¨ [0.1, 0.9] èŒƒå›´ï¼Œé¿å…è¾¹ç•Œå€¼
        coords_map = torch.clamp(coords_map, min=0.1, max=0.9)

        # ğŸ”¥ Step 6: Top-K é€‰æ‹©ï¼ˆå®‰å…¨ç‰ˆæœ¬ï¼‰
        max_K = num_queries.max().item()
        quality_flat = quality_map.flatten(1)  # (BS, H*W)

        actual_k = min(max_K, quality_flat.shape[1])
        if actual_k == 0:
            reference_points = torch.zeros(BS, max_K, 4, device=device)
            reference_points[..., :2] = 0.5
            reference_points[..., 2:] = 0.1
            quality_scores = torch.ones(BS, max_K, device=device) * 0.5
            return reference_points, quality_scores

        # Top-K
        topk_values, topk_indices = torch.topk(quality_flat, actual_k, dim=1)

        # è½¬æ¢ç´¢å¼•
        topk_y = topk_indices // W
        topk_x = topk_indices % W

        # ğŸ”¥ Step 7: æ”¶é›†åæ ‡ï¼ˆå¸¦è¾¹ç•Œæ£€æŸ¥ï¼‰
        reference_points = torch.zeros(BS, max_K, 4, device=device)
        reference_points[..., :2] = 0.5  # é»˜è®¤ä¸­å¿ƒ
        reference_points[..., 2:] = 0.1  # é»˜è®¤å°å°ºå¯¸

        quality_scores = torch.zeros(BS, max_K, device=device)

        for b in range(BS):
            K = min(num_queries[b].item(), actual_k)
            if K > 0:
                try:
                    y_indices = torch.clamp(topk_y[b, :K], 0, H-1)
                    x_indices = torch.clamp(topk_x[b, :K], 0, W-1)
                    coords = coords_map[b, y_indices, x_indices, :]
                    reference_points[b, :K] = coords
                    quality_scores[b, :K] = topk_values[b, :K]
                except Exception as e:
                    print(f"âŒ Coord gathering error for batch {b}: {e}")

        # æœ€ç»ˆæ¸…ç†
        reference_points = torch.clamp(reference_points, min=0.05, max=0.95)
        quality_scores = torch.clamp(quality_scores, min=0.0, max=1.0)

        return reference_points, quality_scores


class DynamicQueryModule(nn.Module):
    """
    åŠ¨æ€æŸ¥è¯¢æ€»æ¨¡å— - æ•°å€¼ç¨³å®šç‰ˆæœ¬
    """

    def __init__(self,
                 feature_dim=256,
                 num_boundaries=3,
                 max_objects=1500,
                 query_levels=None,
                 initial_smoothness=1.0):
        super().__init__()

        if query_levels is None:
            query_levels = [300, 500, 900, 1500]
        self.query_levels = query_levels

        self.boundary_predictor = LearnableBoundaryPredictor(
            feature_dim=feature_dim,
            num_boundaries=num_boundaries,
            max_objects=max_objects,
            initial_smoothness=initial_smoothness
        )

        self.query_initializer = QualityAwareQueryInitializer(
            feature_dim=feature_dim,
            max_queries=max(query_levels)
        )

    def forward(self, density_feature, encoder_feature, real_counts=None, training=True):
        """
        å‰å‘ä¼ æ’­ - å¸¦å®Œæ•´é”™è¯¯å¤„ç†
        """
        BS = density_feature.shape[0]
        device = density_feature.device

        # ğŸ”¥ é¢„æµ‹è¾¹ç•Œï¼ˆå¸¦å¼‚å¸¸æ•è·ï¼‰
        try:
            boundaries, raw_boundaries = self.boundary_predictor(density_feature)
        except Exception as e:
            print(f"âŒ Boundary prediction error: {e}")
            # ä½¿ç”¨é»˜è®¤è¾¹ç•Œ
            boundaries = torch.tensor(
                [[300, 600, 1000]] * BS,
                dtype=torch.float32,
                device=device
            )
            raw_boundaries = torch.zeros(BS, 3, device=device)

        outputs = {
            'boundaries': boundaries,
            'raw_boundaries': raw_boundaries,
        }

        # ğŸ”¥ ç¡®å®šæŸ¥è¯¢æ•°é‡
        if training and real_counts is not None:
            try:
                interval_probs = self.boundary_predictor.compute_interval_probabilities(
                    boundaries, real_counts
                )
                outputs['interval_probs'] = interval_probs
                num_queries = self._get_expected_query_number(interval_probs)
            except Exception as e:
                print(f"âŒ Interval probability error: {e}")
                # ä½¿ç”¨é»˜è®¤æŸ¥è¯¢æ•°é‡
                num_queries = torch.full((BS,), self.query_levels[1], dtype=torch.long, device=device)
                outputs['interval_probs'] = None
        else:
            predicted_count = self._estimate_object_count(density_feature)
            num_queries = self.boundary_predictor.get_query_number(
                boundaries, predicted_count, self.query_levels
            )
            outputs['predicted_count'] = predicted_count

        outputs['num_queries'] = num_queries

        # ğŸ”¥ åˆå§‹åŒ–æŸ¥è¯¢ï¼ˆå¸¦å¼‚å¸¸æ•è·ï¼‰
        try:
            reference_points, quality_scores = self.query_initializer(
                encoder_feature, num_queries
            )
            outputs['reference_points'] = reference_points
            outputs['quality_scores'] = quality_scores
        except Exception as e:
            print(f"âŒ Query initialization error: {e}")
            import traceback
            traceback.print_exc()
            # ä½¿ç”¨å®‰å…¨çš„é»˜è®¤å€¼
            max_K = max(self.query_levels)
            reference_points = torch.zeros(BS, max_K, 4, device=device)
            reference_points[..., :2] = 0.5
            reference_points[..., 2:] = 0.1
            quality_scores = torch.ones(BS, max_K, device=device) * 0.5
            outputs['reference_points'] = reference_points
            outputs['quality_scores'] = quality_scores

        return outputs

    def _get_expected_query_number(self, interval_probs):
        """æ ¹æ®æ¦‚ç‡è®¡ç®—æœŸæœ›æŸ¥è¯¢æ•°é‡"""
        BS = interval_probs.shape[0]
        device = interval_probs.device

        query_levels_tensor = torch.tensor(
            self.query_levels, dtype=torch.float32, device=device
        )

        expected_queries = (interval_probs * query_levels_tensor).sum(dim=1)

        num_queries = torch.zeros(BS, dtype=torch.long, device=device)
        for b in range(BS):
            diffs = torch.abs(query_levels_tensor - expected_queries[b])
            num_queries[b] = self.query_levels[torch.argmin(diffs)]

        return num_queries

    def _estimate_object_count(self, density_feature):
        """ä¼°è®¡ç›®æ ‡æ•°é‡"""
        # ç®€åŒ–ç‰ˆæœ¬ï¼šä½¿ç”¨ç‰¹å¾å›¾çš„å¹³å‡æ¿€æ´»
        count = torch.mean(torch.abs(density_feature), dim=(1, 2, 3)) * 100
        return torch.clamp(count, min=1.0, max=self.query_levels[-1]).long()

    def update_smoothness(self, epoch, total_epochs):
        """æ›´æ–°å¹³æ»‘ç³»æ•°"""
        self.boundary_predictor.update_smoothness(epoch, total_epochs)


def build_dynamic_query_module(args):
    """å·¥å‚å‡½æ•°"""
    return DynamicQueryModule(
        feature_dim=args.hidden_dim,
        num_boundaries=getattr(args, 'num_boundaries', 3),
        max_objects=getattr(args, 'max_objects', 1500),
        query_levels=getattr(args, 'dynamic_query_levels', [300, 500, 900, 1500]),
        initial_smoothness=getattr(args, 'initial_smoothness', 1.0)
    )